# -*- coding: utf-8 -*-
"""streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gVgVtPKR4DxKdLnEvZySnEHSC6k3E15W
"""

# streamlit.py
# NovaPay Fraud Defense (Fast Streamlit App)
# Folder structure expected:
#   ./Models/rf_fraud_model.joblib
#   ./Models/rf_features.json  (recommended)  OR ./novapay_feature_columns.pkl
#   ./shap_values_rf.npy
#   ./X_test_for_shap.csv
#   ./Data/ (optional - for your CSVs)

from __future__ import annotations

import json
from pathlib import Path
from typing import List, Tuple, Optional, Dict

import numpy as np
import pandas as pd
import streamlit as st
import joblib
import matplotlib.pyplot as plt


# -----------------------------
# Paths
# -----------------------------
APP_DIR = Path(__file__).parent
DATA_DIR = APP_DIR / "Data"
MODELS_DIR = APP_DIR / "Models"

MODEL_JOBLIB = MODELS_DIR / "rf_fraud_model.joblib"
FEATURES_JSON = MODELS_DIR / "rf_features.json"
FEATURES_PKL = APP_DIR / "novapay_feature_columns.pkl"

SHAP_VALUES_FILE = APP_DIR / "shap_values_rf.npy"
XTEST_SHAP_FILE = APP_DIR / "X_test_for_shap.csv"


# -----------------------------
# Page setup
# -----------------------------
st.set_page_config(
    page_title="NovaPay | Fraud Defense",
    page_icon="üõ°Ô∏è",
    layout="wide",
)


# -----------------------------
# Light CSS (keep fast)
# -----------------------------
st.markdown(
    """
<style>
.block-container { padding-top: 1.2rem; padding-bottom: 2rem; }
.small-muted { opacity: 0.8; font-size: 0.92rem; }
.kpi { padding: 14px; border-radius: 14px; border: 1px solid rgba(0,0,0,0.08); background: rgba(0,0,0,0.02); }
.kpi .t { font-size: 0.85rem; opacity: 0.75; }
.kpi .v { font-size: 1.4rem; font-weight: 750; }
.badge { display:inline-block; padding:5px 10px; border-radius:999px; background:rgba(0,0,0,0.06); font-size:0.8rem; border:1px solid rgba(0,0,0,0.08); }
.card { padding: 16px; border-radius: 16px; border: 1px solid rgba(0,0,0,0.08); background: white; }
hr.soft { border: none; height: 1px; background: rgba(0,0,0,0.08); margin: 12px 0; }
</style>
""",
    unsafe_allow_html=True,
)


# -----------------------------
# Utilities (FAST + robust)
# -----------------------------
@st.cache_resource
def load_model() -> Optional[object]:
    if not MODEL_JOBLIB.exists():
        return None
    return joblib.load(MODEL_JOBLIB)


@st.cache_resource
def load_feature_list() -> Optional[List[str]]:
    """
    Prefer rf_features.json (list of strings).
    Fallback to novapay_feature_columns.pkl if present.
    """
    if FEATURES_JSON.exists():
        try:
            with open(FEATURES_JSON, "r", encoding="utf-8") as f:
                feats = json.load(f)
            if isinstance(feats, list) and all(isinstance(x, str) for x in feats):
                return feats
        except Exception:
            pass

    if FEATURES_PKL.exists():
        try:
            feats = joblib.load(FEATURES_PKL)
            # could be list or np array
            feats = list(feats)
            return [str(x) for x in feats]
        except Exception:
            pass

    return None


def _timestamp_features(df: pd.DataFrame) -> pd.DataFrame:
    if "timestamp" not in df.columns:
        return df

    ts = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
    df = df.copy()
    df["hour"] = ts.dt.hour.fillna(0).astype(int)
    df["dayofweek"] = ts.dt.dayofweek.fillna(0).astype(int)
    df["month"] = ts.dt.month.fillna(0).astype(int)
    df["is_weekend"] = (ts.dt.dayofweek >= 5).fillna(False).astype(int)
    df.drop(columns=["timestamp"], inplace=True)
    return df


def prepare_features(df: pd.DataFrame, feature_order: List[str]) -> pd.DataFrame:
    """
    Prepare features for inference:
    - timestamp -> hour/dayofweek/month/is_weekend
    - one-hot encode categoricals
    - replace inf/nan
    - align to model feature order (missing -> 0, extra -> drop)
    """
    X = df.copy()

    # drop label if user accidentally uploads it
    if "is_fraud" in X.columns:
        X = X.drop(columns=["is_fraud"])

    X = _timestamp_features(X)

    # numeric cleanup
    X = X.replace([np.inf, -np.inf], np.nan)

    # one-hot encode categoricals
    cat_cols = X.select_dtypes(include=["object", "bool"]).columns.tolist()
    if cat_cols:
        X = pd.get_dummies(X, columns=cat_cols, drop_first=False)

    X = X.fillna(0)

    # align to training feature list
    for col in feature_order:
        if col not in X.columns:
            X[col] = 0

    X = X[feature_order]  # drops extras automatically
    return X


def risk_tier(prob: float) -> str:
    # simple, explainable tiers
    if prob >= 0.85:
        return "Critical"
    if prob >= 0.65:
        return "High"
    if prob >= 0.35:
        return "Medium"
    return "Low"


def score_transactions(
    raw_df: pd.DataFrame,
    model,
    feature_order: List[str],
    threshold: float,
) -> pd.DataFrame:
    X = prepare_features(raw_df, feature_order)
    proba = model.predict_proba(X)[:, 1]
    flag = (proba >= threshold).astype(int)

    out = raw_df.copy()
    out["fraud_probability"] = proba
    out["fraud_flag"] = flag
    out["risk_tier"] = [risk_tier(p) for p in proba]
    return out


def kpi_summary(scored: pd.DataFrame) -> Dict[str, float]:
    total = len(scored)
    flagged = int((scored["fraud_flag"] == 1).sum())
    crit = int((scored["risk_tier"] == "Critical").sum())
    high = int((scored["risk_tier"] == "High").sum())
    avg = float(scored["fraud_probability"].mean()) if total else 0.0
    return dict(total=total, flagged=flagged, critical=crit, high=high, avg_prob=avg)


@st.cache_data
def load_shap_assets() -> Tuple[Optional[np.ndarray], Optional[pd.DataFrame]]:
    """
    SHAP page uses:
      - shap_values_rf.npy  (shape: n_samples x n_features)
      - X_test_for_shap.csv (columns: feature names)
    No is_fraud needed.
    """
    if not (SHAP_VALUES_FILE.exists() and XTEST_SHAP_FILE.exists()):
        return None, None

    shap_vals = np.load(SHAP_VALUES_FILE, allow_pickle=True)
    X_test = pd.read_csv(XTEST_SHAP_FILE)

    # ensure 2D
    if shap_vals.ndim != 2:
        return None, None

    # sanity check alignment
    if shap_vals.shape[1] != X_test.shape[1]:
        return None, None

    return shap_vals, X_test


# -----------------------------
# Header
# -----------------------------
st.markdown(
    """
<div class="card">
  <span class="badge">AI-Assisted Fraud Defense</span>
  <h1 style="margin:0.2rem 0 0.2rem 0;">üõ°Ô∏è NovaPay Fraud Defense Platform</h1>
  <div class="small-muted">
    Score transactions ‚Ä¢ Assign risk tiers ‚Ä¢ Review top-risk cases ‚Ä¢ Explain with SHAP (global)
  </div>
</div>
""",
    unsafe_allow_html=True,
)

st.markdown("<hr class='soft'/>", unsafe_allow_html=True)


# -----------------------------
# Load model + features
# -----------------------------
model = load_model()
features = load_feature_list()

with st.sidebar:
    st.header("üß≠ Navigation")
    page = st.radio(
        "Go to",
        ["Dashboard", "Batch Scoring", "Single Scoring", "Explainability (SHAP)"],
        index=0,
    )

    st.markdown("---")
    st.subheader("‚öôÔ∏è Scoring Control")
    threshold = st.slider("Fraud threshold", 0.10, 0.90, 0.40, 0.05)
    st.caption("Lower = catch more fraud (more alerts). Higher = fewer alerts.")

    st.markdown("---")
    st.subheader("üì¶ Model Status")
    if model is None or features is None:
        st.error("Model or features not found.")
        st.caption("Expected files:")
        st.code(
            "Models/rf_fraud_model.joblib\n"
            "Models/rf_features.json (or novapay_feature_columns.pkl)",
            language="text",
        )
    else:
        st.success("Model ready ‚úÖ")
        st.caption(f"Loaded features: {len(features):,}")


# -----------------------------
# Dashboard
# -----------------------------
if page == "Dashboard":
    c1, c2 = st.columns([1.3, 1])

    with c1:
        st.markdown(
            """
<div class="card">
<h3 style="margin-top:0;">What this app is for</h3>
<ul>
  <li><b>Score</b> each transaction with your trained Random Forest.</li>
  <li>Convert probability into <b>risk tiers</b> (Low ‚Üí Critical).</li>
  <li>Show <b>KPIs</b> that a fraud analyst would report.</li>
  <li>Provide <b>global explainability</b> using saved SHAP artifacts.</li>
</ul>
</div>
""",
            unsafe_allow_html=True,
        )

    with c2:
        st.markdown(
            """
<div class="card">
<h3 style="margin-top:0;">Quick checklist</h3>
<ol>
  <li>Put model in <code>Models/rf_fraud_model.joblib</code></li>
  <li>Put features in <code>Models/rf_features.json</code></li>
  <li>Batch score on the next tab</li>
  <li>Check top risky rows + download results</li>
</ol>
</div>
""",
            unsafe_allow_html=True,
        )

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
    st.subheader("Optional demo preview")

    if model is None or features is None:
        st.info("Fix model loading first (see sidebar).")
    else:
        # Try to show any CSV inside Data folder (if exists)
        csvs = sorted(DATA_DIR.glob("*.csv")) if DATA_DIR.exists() else []
        if not csvs:
            st.info("No CSV found in ./Data. Add one to preview, or use Batch Scoring upload.")
        else:
            pick = st.selectbox("Pick a CSV from Data folder", csvs, format_func=lambda p: p.name)
            df_demo = pd.read_csv(pick)
            st.caption(f"Previewing: {pick.name}")

            scored = score_transactions(df_demo, model, features, threshold=threshold)
            k = kpi_summary(scored)

            m1, m2, m3, m4, m5 = st.columns(5)
            m1.metric("Transactions", f"{k['total']:,}")
            m2.metric("Flagged", f"{k['flagged']:,}")
            m3.metric("Critical", f"{k['critical']:,}")
            m4.metric("High", f"{k['high']:,}")
            m5.metric("Avg Risk", f"{k['avg_prob']:.3f}")

            st.dataframe(scored.head(25), use_container_width=True)


# -----------------------------
# Batch Scoring
# -----------------------------
elif page == "Batch Scoring":
    st.subheader("üß™ Batch Scoring")
    st.caption("Upload a CSV ‚Üí score fraud probability ‚Üí review risk tiers ‚Üí download results.")

    if model is None or features is None:
        st.error("Model not loaded. Fix paths in the sidebar.")
        st.stop()

    uploaded = st.file_uploader("Upload CSV", type=["csv"])
    if uploaded is None:
        st.info("Upload your feature CSV here.")
        st.stop()

    df_in = pd.read_csv(uploaded)

    left, right = st.columns([1.3, 1])
    with left:
        st.markdown("### Preview")
        st.dataframe(df_in.head(30), use_container_width=True)

    with right:
        st.markdown("### Options")
        top_n = st.slider("Top risky rows", 10, 200, 50, 10)
        show_only_flagged = st.checkbox("Show only flagged", value=False)

    with st.spinner("Scoring..."):
        scored = score_transactions(df_in, model, features, threshold=threshold)

    if show_only_flagged:
        view_df = scored[scored["fraud_flag"] == 1].copy()
    else:
        view_df = scored

    k = kpi_summary(scored)
    st.markdown("### KPIs")
    a, b, c, d, e = st.columns(5)
    a.markdown(f"<div class='kpi'><div class='t'>Transactions</div><div class='v'>{k['total']:,}</div></div>", unsafe_allow_html=True)
    b.markdown(f"<div class='kpi'><div class='t'>Flagged</div><div class='v'>{k['flagged']:,}</div></div>", unsafe_allow_html=True)
    c.markdown(f"<div class='kpi'><div class='t'>Critical</div><div class='v'>{k['critical']:,}</div></div>", unsafe_allow_html=True)
    d.markdown(f"<div class='kpi'><div class='t'>High</div><div class='v'>{k['high']:,}</div></div>", unsafe_allow_html=True)
    e.markdown(f"<div class='kpi'><div class='t'>Avg Risk</div><div class='v'>{k['avg_prob']:.3f}</div></div>", unsafe_allow_html=True)

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)

    c1, c2 = st.columns([1, 1.2])

    with c1:
        st.markdown("### üìä Risk Tier Distribution")
        tiers = ["Low", "Medium", "High", "Critical"]
        counts = scored["risk_tier"].value_counts().reindex(tiers).fillna(0)

        fig = plt.figure(figsize=(6, 4))
        plt.bar(counts.index.astype(str), counts.values)
        plt.title("Risk Tier Distribution")
        plt.xlabel("Tier")
        plt.ylabel("Count")
        st.pyplot(fig, clear_figure=True)

    with c2:
        st.markdown("### üî• Top Risk Cases")
        top_risky = scored.sort_values("fraud_probability", ascending=False).head(top_n)
        st.dataframe(top_risky, use_container_width=True)

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
    st.markdown("### Results Table")
    st.dataframe(view_df, use_container_width=True)

    st.markdown("### ‚¨áÔ∏è Download")
    colA, colB = st.columns(2)

    with colA:
        st.download_button(
            "Download FULL scored CSV",
            data=scored.to_csv(index=False).encode("utf-8"),
            file_name="novapay_scored_full.csv",
            mime="text/csv",
        )

    with colB:
        flagged_df = scored[scored["fraud_flag"] == 1]
        st.download_button(
            "Download ONLY flagged fraud",
            data=flagged_df.to_csv(index=False).encode("utf-8"),
            file_name="novapay_scored_flagged_only.csv",
            mime="text/csv",
        )


# -----------------------------
# Single Scoring
# -----------------------------
elif page == "Single Scoring":
    st.subheader("üéØ Single Transaction Scoring")
    st.caption("Enter key fields ‚Üí get probability, tier, decision.")

    if model is None or features is None:
        st.error("Model not loaded. Fix paths in the sidebar.")
        st.stop()

    # Minimal but useful input set (fast + realistic)
    c1, c2, c3 = st.columns(3)
    with c1:
        amount_usd = st.number_input("Amount (USD)", min_value=0.0, value=250.0, step=10.0)
        fee = st.number_input("Fee", min_value=0.0, value=3.0, step=0.1)
        account_age_days = st.number_input("Account age (days)", min_value=0, value=120, step=1)

    with c2:
        ip_risk_score = st.slider("IP risk score", 0.0, 1.0, 0.35, 0.01)
        device_trust_score = st.slider("Device trust score", 0.0, 1.0, 0.70, 0.01)
        corridor_risk = st.slider("Corridor risk", 0.0, 1.0, 0.20, 0.01)

    with c3:
        txn_velocity_1h = st.number_input("Txn velocity (1h)", min_value=0, value=1, step=1)
        txn_velocity_24h = st.number_input("Txn velocity (24h)", min_value=0, value=3, step=1)
        location_mismatch = st.checkbox("Location mismatch", value=False)
        new_device = st.checkbox("New device", value=False)

    run = st.button("üß† Score transaction", type="primary")

    if not run:
        st.info("Enter values and click **Score transaction**.")
        st.stop()

    row = pd.DataFrame([{
        "amount_usd": amount_usd,
        "fee": fee,
        "account_age_days": int(account_age_days),
        "ip_risk_score": ip_risk_score,
        "device_trust_score": device_trust_score,
        "corridor_risk": corridor_risk,
        "txn_velocity_1h": int(txn_velocity_1h),
        "txn_velocity_24h": int(txn_velocity_24h),
        "location_mismatch": bool(location_mismatch),
        "new_device": bool(new_device),
    }])

    scored_one = score_transactions(row, model, features, threshold=threshold)
    prob = float(scored_one["fraud_probability"].iloc[0])
    flag = int(scored_one["fraud_flag"].iloc[0])
    tier = str(scored_one["risk_tier"].iloc[0])

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)

    a, b, c = st.columns([1, 1, 1])
    a.metric("Fraud probability", f"{prob:.4f}")
    b.metric("Risk tier", tier)
    c.metric("Decision", "FLAG" if flag == 1 else "ALLOW")

    if flag == 1:
        st.error("‚ö†Ô∏è Decision: FLAG (send to manual review)")
    else:
        st.success("‚úÖ Decision: ALLOW (monitor)")

    with st.expander("Show scored row"):
        st.dataframe(scored_one, use_container_width=True)


# -----------------------------
# Explainability (SHAP global)
# -----------------------------
elif page == "Explainability (SHAP)":
    st.subheader("üß† Explainability (Global SHAP)")
    st.caption("Uses saved artifacts: shap_values_rf.npy + X_test_for_shap.csv (no is_fraud needed).")

    shap_vals, X_test = load_shap_assets()
    if shap_vals is None or X_test is None:
        st.warning(
            "SHAP assets not found or mismatched.\n\n"
            "Expected:\n"
            "- shap_values_rf.npy (2D: samples x features)\n"
            "- X_test_for_shap.csv (same number of feature columns)\n"
        )
        st.stop()

    # Mean absolute SHAP
    mean_abs = np.abs(shap_vals).mean(axis=0)
    fi = (
        pd.DataFrame({"feature": X_test.columns, "mean_abs_shap": mean_abs})
        .sort_values("mean_abs_shap", ascending=False)
        .reset_index(drop=True)
    )

    top_k = st.slider("Top features to show", 10, 50, 20, 5)

    st.markdown("### Top Features (Mean |SHAP|)")
    st.dataframe(fi.head(top_k), use_container_width=True)

    # Bar chart
    fig = plt.figure(figsize=(8, 6))
    show = fi.head(top_k).iloc[::-1]
    plt.barh(show["feature"], show["mean_abs_shap"])
    plt.title(f"Top {top_k} Features by Mean |SHAP|")
    plt.xlabel("Mean |SHAP value|")
    st.pyplot(fig, clear_figure=True)

    st.info(
        "If you also want beeswarm/force plots inside Streamlit, we can add them, "
        "but global bar importance is the fastest + most stable for grading."
    )